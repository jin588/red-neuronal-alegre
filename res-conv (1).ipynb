{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-12-07 12:24:39.593132: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers,Sequential\n",
    "from tensorflow.python.client import device_lib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 28821 files belonging to 7 classes.\n",
      "Using 23057 files for training.\n",
      "Using 5764 files for validation.\n"
     ]
    }
   ],
   "source": [
    "image_size = (48, 48)\n",
    "batch_size = 64\n",
    "\n",
    "train_ds, val_ds = tf.keras.utils.image_dataset_from_directory(\n",
    "    \"data/data/images/train\",\n",
    "    label_mode='categorical',\n",
    "    color_mode=\"grayscale\",\n",
    "    validation_split=0.2,\n",
    "    subset=\"both\",\n",
    "    shuffle=True,\n",
    "    seed=666,\n",
    "    image_size=image_size,\n",
    "    batch_size=batch_size,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.layers import Dense, Input, Dropout, GlobalAveragePooling2D, Flatten, Conv2D, BatchNormalization, Activation, MaxPooling2D\n",
    "from keras.models import Model, Sequential\n",
    "from keras.optimizers import Adam\n",
    "\n",
    "# number of possible label values\n",
    "nb_classes = 7\n",
    "\n",
    "# Initialising the CNN\n",
    "model = Sequential()\n",
    "\n",
    "# 1 - Convolution\n",
    "model.add(Conv2D(64,(3,3), padding='same', input_shape=(48, 48,1)))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Activation('relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model.add(Dropout(0.25))\n",
    "\n",
    "# 2nd Convolution layer\n",
    "model.add(Conv2D(128,(5,5), padding='same'))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Activation('relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model.add(Dropout(0.25))\n",
    "\n",
    "# 3rd Convolution layer\n",
    "model.add(Conv2D(512,(3,3), padding='same'))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Activation('relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model.add(Dropout(0.25))\n",
    "\n",
    "# 4th Convolution layer\n",
    "model.add(Conv2D(512,(3,3), padding='same'))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Activation('relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model.add(Dropout(0.25))\n",
    "\n",
    "# Flattening\n",
    "model.add(Flatten())\n",
    "\n",
    "# Fully connected layer 1st layer\n",
    "model.add(Dense(256))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Activation('relu'))\n",
    "model.add(Dropout(0.25))\n",
    "\n",
    "# Fully connected layer 2nd layer\n",
    "model.add(Dense(512))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Activation('relu'))\n",
    "model.add(Dropout(0.25))\n",
    "\n",
    "model.add(Dense(nb_classes, activation='softmax'))\n",
    "\n",
    "model.compile( loss='categorical_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_2\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d_25 (Conv2D)          (None, 48, 48, 64)        640       \n",
      "                                                                 \n",
      " batch_normalization_25 (Ba  (None, 48, 48, 64)        256       \n",
      " tchNormalization)                                               \n",
      "                                                                 \n",
      " activation_27 (Activation)  (None, 48, 48, 64)        0         \n",
      "                                                                 \n",
      " max_pooling2d_13 (MaxPooli  (None, 24, 24, 64)        0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " dropout_17 (Dropout)        (None, 24, 24, 64)        0         \n",
      "                                                                 \n",
      " conv2d_26 (Conv2D)          (None, 24, 24, 128)       204928    \n",
      "                                                                 \n",
      " batch_normalization_26 (Ba  (None, 24, 24, 128)       512       \n",
      " tchNormalization)                                               \n",
      "                                                                 \n",
      " activation_28 (Activation)  (None, 24, 24, 128)       0         \n",
      "                                                                 \n",
      " max_pooling2d_14 (MaxPooli  (None, 12, 12, 128)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " dropout_18 (Dropout)        (None, 12, 12, 128)       0         \n",
      "                                                                 \n",
      " conv2d_27 (Conv2D)          (None, 12, 12, 512)       590336    \n",
      "                                                                 \n",
      " batch_normalization_27 (Ba  (None, 12, 12, 512)       2048      \n",
      " tchNormalization)                                               \n",
      "                                                                 \n",
      " activation_29 (Activation)  (None, 12, 12, 512)       0         \n",
      "                                                                 \n",
      " max_pooling2d_15 (MaxPooli  (None, 6, 6, 512)         0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " dropout_19 (Dropout)        (None, 6, 6, 512)         0         \n",
      "                                                                 \n",
      " conv2d_28 (Conv2D)          (None, 6, 6, 512)         2359808   \n",
      "                                                                 \n",
      " batch_normalization_28 (Ba  (None, 6, 6, 512)         2048      \n",
      " tchNormalization)                                               \n",
      "                                                                 \n",
      " activation_30 (Activation)  (None, 6, 6, 512)         0         \n",
      "                                                                 \n",
      " max_pooling2d_16 (MaxPooli  (None, 3, 3, 512)         0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " dropout_20 (Dropout)        (None, 3, 3, 512)         0         \n",
      "                                                                 \n",
      " flatten_7 (Flatten)         (None, 4608)              0         \n",
      "                                                                 \n",
      " dense_25 (Dense)            (None, 256)               1179904   \n",
      "                                                                 \n",
      " batch_normalization_29 (Ba  (None, 256)               1024      \n",
      " tchNormalization)                                               \n",
      "                                                                 \n",
      " activation_31 (Activation)  (None, 256)               0         \n",
      "                                                                 \n",
      " dropout_21 (Dropout)        (None, 256)               0         \n",
      "                                                                 \n",
      " dense_26 (Dense)            (None, 512)               131584    \n",
      "                                                                 \n",
      " batch_normalization_30 (Ba  (None, 512)               2048      \n",
      " tchNormalization)                                               \n",
      "                                                                 \n",
      " activation_32 (Activation)  (None, 512)               0         \n",
      "                                                                 \n",
      " dropout_22 (Dropout)        (None, 512)               0         \n",
      "                                                                 \n",
      " dense_27 (Dense)            (None, 7)                 3591      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 4478727 (17.08 MB)\n",
      "Trainable params: 4474759 (17.07 MB)\n",
      "Non-trainable params: 3968 (15.50 KB)\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs = 15\n",
    "\n",
    "callbacks = [\n",
    "    keras.callbacks.ModelCheckpoint(\"models/save_at_{epoch}.keras\"),\n",
    "    keras.callbacks.EarlyStopping(patience=5)\n",
    "]\n",
    "model.compile(\n",
    "    optimizer=keras.optimizers.Adam(learning_rate=1e-3),\n",
    "    loss=\"categorical_crossentropy\",\n",
    "    metrics=[\"accuracy\"],\n",
    ")\n",
    "history = model.fit(\n",
    "    train_ds,\n",
    "    epochs=epochs,\n",
    "    callbacks=callbacks,\n",
    "    validation_data=val_ds,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_history_loss(history):\n",
    "    tr_acc = history.history['accuracy']\n",
    "    tr_loss = history.history['loss']\n",
    "    val_acc = history.history['val_accuracy']\n",
    "    val_loss = history.history['val_loss']\n",
    "    index_loss = np.argmin(val_loss)\n",
    "    val_lowest = val_loss[index_loss]\n",
    "    index_acc = np.argmax(val_acc)\n",
    "    acc_highest = val_acc[index_acc]\n",
    "    Epochs = [i+1 for i in range(len(tr_acc))]\n",
    "    loss_label = f'best epoch= {str(index_loss + 1)}'\n",
    "    acc_label = f'best epoch= {str(index_acc + 1)}'\n",
    "    # Plot training history\n",
    "    plt.figure(figsize= (20, 8))\n",
    "    plt.style.use('fivethirtyeight')\n",
    "    plt.subplot(1, 2, 1)\n",
    "    plt.plot(Epochs, tr_loss, 'r', label= 'Training loss')\n",
    "    plt.plot(Epochs, val_loss, 'g', label= 'Validation loss')\n",
    "    plt.scatter(index_loss + 1, val_lowest, s= 150, c= 'blue', label= loss_label)\n",
    "    plt.title('Training and Validation Loss')\n",
    "    plt.xlabel('Epochs')\n",
    "    plt.ylabel('Loss')\n",
    "    plt.legend()\n",
    "    plt.subplot(1, 2, 2)\n",
    "    plt.plot(Epochs, tr_acc, 'r', label= 'Training Accuracy')\n",
    "    plt.plot(Epochs, val_acc, 'g', label= 'Validation Accuracy')\n",
    "    plt.scatter(index_acc + 1 , acc_highest, s= 150, c= 'blue', label= acc_label)\n",
    "    plt.title('Training and Validation Accuracy')\n",
    "    plt.xlabel('Epochs')\n",
    "    plt.ylabel('Accuracy')\n",
    "    plt.legend()\n",
    "\n",
    "    plt.tight_layout\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import os\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "TEST_IMAGE_PATH = os.getcwd() + '/data/data/images/test'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "list_img = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "for file in os.listdir(TEST_IMAGE_PATH):\n",
    "    try:\n",
    "        file_path = os.path.join(TEST_IMAGE_PATH, file)\n",
    "        img = cv2.imread(file_path, cv2.IMREAD_GRAYSCALE)\n",
    "        list_img.append(img.flatten())\n",
    "    except Exception as e:\n",
    "        print(\"Error: \",e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2304,)"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list_img[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_history_loss(history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import load_model\n",
    "\n",
    "final_modal = load_model(\"models/save_at_X.keras\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['angry', 'disgust', 'fear', 'happy', 'neutral', 'sad', 'surprise']"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class_names = train_ds.class_names\n",
    "class_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Forma de X_test: (16280064,)\n",
      "Forma de y_test: (5764, 7)\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "in user code:\n\n    File \"/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/keras/src/engine/training.py\", line 2440, in predict_function  *\n        return step_function(self, iterator)\n    File \"/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/keras/src/engine/training.py\", line 2425, in step_function  **\n        outputs = model.distribute_strategy.run(run_step, args=(data,))\n    File \"/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/keras/src/engine/training.py\", line 2413, in run_step  **\n        outputs = model.predict_step(data)\n    File \"/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/keras/src/engine/training.py\", line 2381, in predict_step\n        return self(x, training=False)\n    File \"/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/keras/src/utils/traceback_utils.py\", line 70, in error_handler\n        raise e.with_traceback(filtered_tb) from None\n    File \"/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/keras/src/engine/input_spec.py\", line 253, in assert_input_compatibility\n        raise ValueError(\n\n    ValueError: Exception encountered when calling layer 'sequential_2' (type Sequential).\n    \n    Input 0 of layer \"conv2d_25\" is incompatible with the layer: expected min_ndim=4, found ndim=1. Full shape received: (32,)\n    \n    Call arguments received by layer 'sequential_2' (type Sequential):\n      • inputs=tf.Tensor(shape=(32,), dtype=uint8)\n      • training=False\n      • mask=None\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m/Users/javierdealcazar/TheBridgeDataScience/red-neuronal-alegres/res-conv.ipynb Cell 12\u001b[0m line \u001b[0;36m1\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/javierdealcazar/TheBridgeDataScience/red-neuronal-alegres/res-conv.ipynb#X20sZmlsZQ%3D%3D?line=15'>16</a>\u001b[0m     assigned_number \u001b[39m=\u001b[39m position_of_1\u001b[39m.\u001b[39mnumpy()\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/javierdealcazar/TheBridgeDataScience/red-neuronal-alegres/res-conv.ipynb#X20sZmlsZQ%3D%3D?line=16'>17</a>\u001b[0m     assigned_numbers\u001b[39m.\u001b[39mappend(assigned_number)\n\u001b[0;32m---> <a href='vscode-notebook-cell:/Users/javierdealcazar/TheBridgeDataScience/red-neuronal-alegres/res-conv.ipynb#X20sZmlsZQ%3D%3D?line=18'>19</a>\u001b[0m y_pred \u001b[39m=\u001b[39m model\u001b[39m.\u001b[39;49mpredict(X_test)\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/javierdealcazar/TheBridgeDataScience/red-neuronal-alegres/res-conv.ipynb#X20sZmlsZQ%3D%3D?line=19'>20</a>\u001b[0m results \u001b[39m=\u001b[39m model\u001b[39m.\u001b[39mevaluate(X_test, y_test)\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/javierdealcazar/TheBridgeDataScience/red-neuronal-alegres/res-conv.ipynb#X20sZmlsZQ%3D%3D?line=20'>21</a>\u001b[0m \u001b[39mprint\u001b[39m(results)\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/keras/src/utils/traceback_utils.py:70\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     67\u001b[0m     filtered_tb \u001b[39m=\u001b[39m _process_traceback_frames(e\u001b[39m.\u001b[39m__traceback__)\n\u001b[1;32m     68\u001b[0m     \u001b[39m# To get the full stack trace, call:\u001b[39;00m\n\u001b[1;32m     69\u001b[0m     \u001b[39m# `tf.debugging.disable_traceback_filtering()`\u001b[39;00m\n\u001b[0;32m---> 70\u001b[0m     \u001b[39mraise\u001b[39;00m e\u001b[39m.\u001b[39mwith_traceback(filtered_tb) \u001b[39mfrom\u001b[39;00m \u001b[39mNone\u001b[39;00m\n\u001b[1;32m     71\u001b[0m \u001b[39mfinally\u001b[39;00m:\n\u001b[1;32m     72\u001b[0m     \u001b[39mdel\u001b[39;00m filtered_tb\n",
      "File \u001b[0;32m/var/folders/28/8cl0hx0s7wn3jhrkn9jsr1780000gp/T/__autograph_generated_filehz58zwtb.py:15\u001b[0m, in \u001b[0;36mouter_factory.<locals>.inner_factory.<locals>.tf__predict_function\u001b[0;34m(iterator)\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m     14\u001b[0m     do_return \u001b[39m=\u001b[39m \u001b[39mTrue\u001b[39;00m\n\u001b[0;32m---> 15\u001b[0m     retval_ \u001b[39m=\u001b[39m ag__\u001b[39m.\u001b[39mconverted_call(ag__\u001b[39m.\u001b[39mld(step_function), (ag__\u001b[39m.\u001b[39mld(\u001b[39mself\u001b[39m), ag__\u001b[39m.\u001b[39mld(iterator)), \u001b[39mNone\u001b[39;00m, fscope)\n\u001b[1;32m     16\u001b[0m \u001b[39mexcept\u001b[39;00m:\n\u001b[1;32m     17\u001b[0m     do_return \u001b[39m=\u001b[39m \u001b[39mFalse\u001b[39;00m\n",
      "\u001b[0;31mValueError\u001b[0m: in user code:\n\n    File \"/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/keras/src/engine/training.py\", line 2440, in predict_function  *\n        return step_function(self, iterator)\n    File \"/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/keras/src/engine/training.py\", line 2425, in step_function  **\n        outputs = model.distribute_strategy.run(run_step, args=(data,))\n    File \"/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/keras/src/engine/training.py\", line 2413, in run_step  **\n        outputs = model.predict_step(data)\n    File \"/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/keras/src/engine/training.py\", line 2381, in predict_step\n        return self(x, training=False)\n    File \"/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/keras/src/utils/traceback_utils.py\", line 70, in error_handler\n        raise e.with_traceback(filtered_tb) from None\n    File \"/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/keras/src/engine/input_spec.py\", line 253, in assert_input_compatibility\n        raise ValueError(\n\n    ValueError: Exception encountered when calling layer 'sequential_2' (type Sequential).\n    \n    Input 0 of layer \"conv2d_25\" is incompatible with the layer: expected min_ndim=4, found ndim=1. Full shape received: (32,)\n    \n    Call arguments received by layer 'sequential_2' (type Sequential):\n      • inputs=tf.Tensor(shape=(32,), dtype=uint8)\n      • training=False\n      • mask=None\n"
     ]
    }
   ],
   "source": [
    "\n",
    "X_test = np.concatenate(list_img)\n",
    "print(\"Forma de X_test:\", X_test.shape)\n",
    "\n",
    "y_pred = final_modal.predict(X_test)\n",
    "y_pred\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
